# Workers

Blocking computations should not run on the main event loop as they would block all other requests. ecewo provides the `spawn()` and `spawn_http()` functions to handle blocking operations safely by executing them in [libuv](https://libuv.org/)'s thread pool.

## Table of Contents

1. [`spawn()`](#spawn)
2. [`spawn_http()`](#spawn_http)
2. [The spawn() Function](#the-spawn-function)
3. [Fire-and-forget](#fire-and-forget)
4. [Wait and Respond](#wait-and-respond)
5. [Notes](#notes)

## `spawn()`

The `spawn()` function executes blocking work in a worker thread and runs a callback on the main thread when complete. It is suitable for fire-and-forget tasks.

**Signature:**
```c
int spawn(void *context, spawn_handler_t work_fn, spawn_handler_t done_fn);
```

**Parameters:**
- `context`: User context pointer (must contain arena for memory allocation)
- `work_fn`: Function to execute in worker thread (safe to block here)
- `done_fn`: Callback when work completes (runs on main thread, can be NULL)

**Returns:**
- `0` on success
- `-1` on failure

**Callback Signature:**
```c
typedef void (*spawn_handler_t)(void *context);
```

### Basic Usage

```c
#include "ecewo.h"
#include <stdio.h>

typedef struct {
  Arena *arena;
  int iterations;
} ComputeContext;

// This runs in a worker thread (safe to block)
void calculate_primes(void *context) {
  ComputeContext *ctx = (ComputeContext *)context;
  
  printf("Computing primes up to %d...\n", ctx->iterations);
  
  int prime_count = 0;
  
  // CPU-intensive loop
  for (int num = 2; num <= ctx->iterations; num++) {
    int is_prime = 1;
    
    for (int i = 2; i * i <= num; i++) {
      if (num % i == 0) {
        is_prime = 0;
        break;
      }
    }
    
    if (is_prime)
      prime_count++;
  }
  
  printf("Found %d primes\n", prime_count);

  arena_return(ctx->arena);
}

void compute_handler(Req *req, Res *res) {
  const char *iter_str = get_query(req, "iterations");
  int iterations = atoi(iter_str);
  
  // Create independent arena for background work
  Arena *bg_arena = arena_borrow();
  
  ComputeContext *ctx = arena_alloc(bg_arena, sizeof(ComputeContext));
  ctx->arena = bg_arena;
  ctx->iterations = iterations;
  
  // Offload to worker thread
  spawn(ctx, calculate_primes, NULL);
  
  // Handler returns immediately
  // Computation will work on background
  char *msg = arena_sprintf(req->arena, "Computation started");
  send_text(res, ACCEPTED, msg);
}

int main(void) {
  server_init();
  
  get("/compute", compute_handler);
  
  server_listen(3000);
  server_run();
  
  return 0;
}
```

Go to `http://localhost:3000/compute?iterations=10000` address.

### Advanced Example

Here's a more complex example with multiple parallel tasks:

```c
#include "ecewo.h"

typedef struct {
  Arena *arena;
  int total;
  int completed;
  int results[3];
} ParallelContext;

static void parallel_work_1(void *context) {
  ParallelContext *ctx = (ParallelContext *)context;
  
  // CPU-intensive work
  int sum = 0;
  for (int i = 0; i < 100000000; i++) {
    sum += i % 100;
  }
  
  ctx->results[0] = sum % 1000;
}

static void parallel_work_2(void *context) {
  ParallelContext *ctx = (ParallelContext *)context;
  
  int product = 1;
  for (int i = 1; i < 1000000; i++) {
    product = (product * i) % 10000;
  }
  
  ctx->results[1] = product % 1000;
}

static void parallel_work_3(void *context) {
  ParallelContext *ctx = (ParallelContext *)context;
  
  int count = 0;
  for (int i = 2; i < 100000; i++) {
    int is_prime = 1;
    for (int j = 2; j * j <= i; j++) {
      if (i % j == 0) {
        is_prime = 0;
        break;
      }
    }
    if (is_prime)
      count++;
  }
  
  ctx->results[2] = count % 1000;
}

static void parallel_done(void *context) {
  ParallelContext *ctx = (ParallelContext *)context;
  ctx->completed++;
  
  // All tasks completed
  if (ctx->completed == ctx->total) {
    int sum = ctx->results[0] + ctx->results[1] + ctx->results[2];

    printf("Background calculation completed. Sum: %d\n", sum);
    printf("  Task 1: %d\n", ctx->results[0]);
    printf("  Task 2: %d\n", ctx->results[1]);
    printf("  Task 3: %d\n", ctx->results[2]);
    
    arena_return(ctx->arena);
  }
}

void parallel_handler(Req *req, Res *res) {
  Arena *bg_arena = arena_borrow();

  ParallelContext *ctx = arena_alloc(bg_arena, sizeof(ParallelContext));
  ctx->arena = bg_arena;
  ctx->total = 3;
  ctx->completed = 0;
  ctx->results[0] = 0;
  ctx->results[1] = 0;
  ctx->results[2] = 0;
  
  // Launch 3 parallel tasks
  spawn(ctx, parallel_work_1, parallel_done);
  spawn(ctx, parallel_work_2, parallel_done);
  spawn(ctx, parallel_work_3, parallel_done);

  // Send response immediately
  // Computation will work on background
  send_text(res, ACCEPTED, "Calculation started in background");
}
```

## `spawn_http()`

The `spawn_http()` function is basically same as `spawn()`. If you need to send a response to the client after the blocking operation has been done, use `spawn_http()` instead of `spawn()`.

It is also usable for blocking database queries, such as SQLite. See the [SQLite Example](./examples/using_sqlite.md).

**Signature:**
```c
int spawn_http(Res *res, void *context, spawn_handler_t work_fn, spawn_done_t done_fn);
```

**Parameters:**
- `context`: User context pointer (must contain arena for memory allocation)
- `work_fn`: Function to execute in worker thread (safe to block here)
- `done_fn`: Callback when work completes (runs on main thread, can be NULL)

**Returns:**
- `0` on success
- `-1` on failure

**Callback Signature:**
```c
typedef void (*spawn_handler_t)(void *context);
typedef void (*spawn_done_t)(Res *res, void *context);
```

### Basic Usage

```c
#include "ecewo.h"

typedef struct {
  int result;
} ComputeContext;

// This runs in a worker thread (safe to block)
void heavy_computation(void *context) {
  ComputeContext *ctx = (ComputeContext *)context;
  
  // Simulate CPU-intensive work
  int sum = 0;
  for (int i = 0; i < 1000000000; i++) {
    sum += i;
  }
  
  ctx->result = sum;
}

// This runs on the main thread when heavy_computation is done
void computation_complete(Res *res, void *context) {
  ComputeContext *ctx = (ComputeContext *)context;
  
  char *response = arena_sprintf(res->arena, 
                   "Computation result: %d", 
                   ctx->result);
  
  send_text(res, 200, response);
}

// Route handler (runs on main thread)
void compute_handler(Req *req, Res *res) {
  // Create context (arena-allocated)
  ComputeContext *ctx = arena_alloc(res->arena, sizeof(ComputeContext));
  ctx->result = 0;
  
  // Spawn the work
  spawn_http(res, ctx, heavy_computation, computation_complete);
  
  // Handler returns immediately
  // Response is sent when computation_complete runs
}

int main(void) {
  server_init();
  
  get("/compute", compute_handler);
  
  server_listen(3000);
  server_run();
  
  return 0;
}
```

### Advanced Example

```c
#include "ecewo.h"

typedef struct {
  int total;
  int completed;
  int results[3];
  bool has_error;
} ParallelContext;

static void parallel_work_1(void *context) {
  ParallelContext *ctx = (ParallelContext *)context;
  
  // Simulate CPU-intensive work
  // In real code: database query, file I/O, API call, etc.
  ctx->results[0] = 10;
}

static void parallel_work_2(void *context) {
  ParallelContext *ctx = (ParallelContext *)context;
  ctx->results[1] = 20;
}

static void parallel_work_3(void *context) {
  ParallelContext *ctx = (ParallelContext *)context;
  ctx->results[2] = 30;
}

static void parallel_done(Res *res, void *context) {
  ParallelContext *ctx = (ParallelContext *)context;
  ctx->completed++;
  
  // If any spawn failed
  if (ctx->has_error && ctx->completed == 1) {
    send_text(res, 500, "Task spawn failed");
    return;
  }
  
  // All tasks completed successfully
  if (ctx->completed == ctx->total && !ctx->has_error) {
    int sum = ctx->results[0] + ctx->results[1] + ctx->results[2];
    char *response = arena_sprintf(res->arena, "{\"sum\":%d}", sum);
    send_json(res, 200, response);
  }
}

void parallel_handler(Req *req, Res *res) {
  ParallelContext *ctx = arena_alloc(res->arena, sizeof(ParallelContext));
  ctx->total = 3;
  ctx->completed = 0;
  ctx->results[0] = 0;
  ctx->results[1] = 0;
  ctx->results[2] = 0;
  ctx->has_error = false;
  
  // Launch 3 parallel tasks
  if (spawn_http(res, ctx, parallel_work_1, parallel_done) != 0)
    ctx->has_error = true;
  if (spawn_http(res, ctx, parallel_work_2, parallel_done) != 0)
    ctx->has_error = true;
  if (spawn_http(res, ctx, parallel_work_3, parallel_done) != 0)
    ctx->has_error = true;
  
  // If all spawns failed
  if (ctx->has_error && ctx->completed == 0)
    send_text(res, 500, "Failed to spawn tasks");
}

// ===== ROUTE REGISTRATION =====

int main(void) {
  server_init();
  
  get("/parallel", parallel_handler);
  
  server_listen(3000);
  server_run();
  
  return 0;
}
```

## Notes

> [!IMPORTANT]
>
> The `spawn()` function uses libuv's thread pool (default: 4 threads). All blocking operations share this pool, so tasks may wait if all threads are busy. Set `UV_THREADPOOL_SIZE` environment variable to increase the thread pool size if needed.

```c
// If you have many concurrent requests with spawn(),
// increase thread pool size before starting server:

int main(void) {
  // Set thread pool size (default is 4)
  setenv("UV_THREADPOOL_SIZE", "16", 1);
  
  server_init();
  get("/task", task_handler);
  server_listen(3000);
  server_run();
  
  return 0;
}
```

> [!CAUTION]
>
> Never send response in work function.

```c
// WRONG - work_fn runs in worker thread
void wrong_work(void *context) {
  MyContext *ctx = (MyContext *)context;
  send_text(ctx->res, 200, "Done"); // BUG!
}

// CORRECT - send response in done_fn
void correct_done(void *context) {
  MyContext *ctx = (MyContext *)context;
  send_text(ctx->res, 200, "Done"); // Runs on main thread
}
```
