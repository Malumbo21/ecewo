# Async Operations

Since Ecewo is built on top of [libuv](https://libuv.org/), the event-loop works asynchronous. Ecewo provides libuv's API as more comprehensive and easier to use.

## Table of Contents

1. [CPU-Bound Async](#cpu-bound-async)
    1. [Handler-Level Worker](#handler-level-worker)
    2. [Task-Level Worker](#task-level-worker)
    3. [Summary](#summary)
2. [I/O Bound Async](#io-bound-async)
    1. [Async Database Queries](#async-database-queries)
3. [When To Use Each API?](#when-to-use-each-api)

## CPU-Bound Async

Blocking computations should not run on the main event loop as they would block all other requests. Ecewo provides two approaches to handle blocking operations safely:

1. **Handler-Level Worker**: Run the entire handler in a worker thread
2. **Task-Level Worker**: Run specific tasks in worker threads while the handler stays on the main thread

The `worker` is for executing blocking operations in a worker thread without blocking the event loop. It runs the provided handler on a thread where blocking is acceptable. The handler will be executed in a worker thread from the libuv's thread pool. It's safe to write blocking code in it, such as heavy computations.

Both approaches use libuv's thread pool. The pool size is controlled by the `UV_THREADPOOL_SIZE` environment variable (default: 4 threads). All blocking operations share this pool, so requests may wait if all threads are busy. Therefore you can increase the pool size if it's not enough for your project.

### Handler-level Worker

Handler-level worker runs the **entire handler** in a worker thread. Therefore, each request is assigned single worker thread from libuv's thread pool.

Use this for:
- Sequential blocking operations
- Single blocking task per request
- When the whole handler needs to block

To register a handler-level async route, use the `*_worker()` variants:

| Regular (Event Loop) | Worker Thread    |
|----------------------|------------------|
| `get()`              | `get_worker()`   |
| `post()`             | `post_worker()`  |
| `put()`              | `put_worker()`   |
| `del()`              | `del_worker()`   |
| `patch()`            | `patch_worker()` |

A basic example:

```c
void cpu_bound_handler(Req *req, Res *res)
{
    const char *step1_result = cpu_process_step1(req);
    const char *step2_result = cpu_process_step2(step1_result);
    const char *step3_result = cpu_process_step3(step2_result);
    
    reply(res, OK, step3_result, strlen(step3_result));
}

get("/cpu", cpu_bound_handler); // DO NOT DO THIS!
// This will block the main thread and make the entire
// application wait until the handler responds

get_worker("/cpu", cpu_bound_handler); // DO THIS INSTEAD
// This runs the handler in a worker thread,
// so the main thread is never blocked
```

### Task-level Worker

Task-level worker allows you to run multiple independent blocking operations in parallel within a single handler. The handler remains on the main thread, but each task runs in its own worker thread.

Use the `worker()` function for this approach.

**When to use:**
- Multiple independent blocking operations
- Operations that can run in parallel
- Need faster response times (parallel execution)

Let's see how it works doing an example that runs 3 independent tasks as paralelly.

```c
#include "ecewo.h"
#include <stdio.h>
#include <stdbool.h>

// Context for parallel operations
typedef struct {
    Res *res;

    // Task management
    int total_tasks;
    int completed_tasks;
    bool response_sent;

    // Task results
    const char *task1_result;
    const char *task2_result;
    const char *task3_result;
} ParallelContext;

// ===== TASK FUNCTIONS =====
// These run in worker threads (safe to block)

void task1(Task *task, void *context)
{
    ParallelContext *ctx = (ParallelContext *)context;
    
    // Blocking operation 1 (e.g., heavy computation)
    // This runs in a worker thread, safe to block
    ctx->task1_result = "Task 1 completed";
}

void task2(Task *task, void *context)
{
    ParallelContext *ctx = (ParallelContext *)context;
    
    // Blocking operation 2 (e.g., external API call)
    // This runs in a worker thread, safe to block
    ctx->task2_result = "Task 2 completed";
}

void task3(Task *task, void *context)
{
    ParallelContext *ctx = (ParallelContext *)context;
    
    // Blocking operation 3 (e.g., image processing)
    // This runs in a worker thread, safe to block
    ctx->task3_result = "Task 3 completed";
}

// ===== COMPLETION HANDLER =====
// This runs on the main thread when each task finishes

void completion_cb(void *context, char *error)
{
    ParallelContext *ctx = (ParallelContext *)context;
    
    // Skip if response already sent
    if (ctx->response_sent)
        return;
    
    // Handle system errors (very rare)
    if (error)
    {
        ctx->response_sent = true;
        fprintf(stderr, "System error: %s\n", error);
        send_text(ctx->res, 500, error);
        return;
    }
    
    // Track progress
    ctx->completed_tasks++;
    
    // All tasks finished?
    if (ctx->completed_tasks == ctx->total_tasks)
    {
        // All tasks done - send response
        char *response = ecewo_sprintf(ctx->res,
            "All tasks completed:\n"
            "- Task 1: %s\n"
            "- Task 2: %s\n"
            "- Task 3: %s\n",
            ctx->task1_result,
            ctx->task2_result,
            ctx->task3_result
        );
        
        ctx->response_sent = true;
        send_text(ctx->res, 200, response);
    }
}

// ===== ROUTE HANDLER =====
// This runs on the main thread

void parallel_handler(Req *req, Res *res)
{
    // Create context (arena-allocated)
    ParallelContext *ctx = ecewo_alloc(res, sizeof(ParallelContext));
    ctx->res = res;
    
    // Initialize
    ctx->total_tasks = 3;
    ctx->completed_tasks = 0;
    ctx->response_sent = false;
    ctx->task1_result = NULL;
    ctx->task2_result = NULL;
    ctx->task3_result = NULL;
    
    // Launch 3 parallel tasks
    // Each runs in its own worker thread
    worker(ctx, task1, completion_cb);
    worker(ctx, task2, completion_cb);
    worker(ctx, task3, completion_cb);
    
    // Response NOT sent here!
    // completion_cb sends when all tasks finish
}

// ===== ROUTE REGISTRATION =====

int main(void)
{
    server_init();
    
    // CORRECT: Use regular get()
    get("/parallel", parallel_handler);
    
    // WRONG: Don't use get_worker()
    // get_worker("/parallel", parallel_handler);
    
    server_listen(3000);
    server_run();
    
    return 0;
}
```

> [!IMPORTANT]  
> 
> **Use Regular Routes with `worker()`**
>
> When using `worker()` function for parallel operations, always register routes with regular macros like `get()`, `post()`, etc. **Do NOT use** `get_worker()`, `post_worker()`, or any other `*_worker()` variants.
>
> **Why?** Because the `worker()` function manages worker threads internally. The handler itself runs on the main thread and shouldn't be moved to a worker thread.

### Summary

In short, the difference between the `*_worker()` router and the `worker()` function is that the `*_worker()` router runs the entire handler in a worker thread, and costs one worker thread per request. It is suitable for sequential workflows or single tasks that will run on a single thread.

In contrast, the `worker()` function runs specific tasks within the handler on worker threads, rather than executing the whole handler on a single worker thread. As a result, it may consume more than one worker thread per request. It is suitable for independent parallel tasks that will run on multiple threads.

**Example comparison:**

```c
// Handler-Level: Sequential (9 minutes, 1 thread)
void sequential_handler(Req *req, Res *res) {
    char *step1 = blocking_op_1();  // 3 minutes
    char *step2 = blocking_op_2();  // 3 minutes  
    char *step3 = blocking_op_3();  // 3 minutes
    send_text(res, 200, step3);
}
get_worker("/sequential", sequential_handler);

// Task-Level: Parallel (3 minutes, 3 threads)
void parallel_handler(Req *req, Res *res) {
    Context *ctx = ecewo_alloc(res, sizeof(Context));
    task(ctx, task_fn_1, callback);  // 3 minutes
    task(ctx, task_fn_2, callback);  // 3 minutes
    task(ctx, task_fn_3, callback);  // 3 minutes
    // All run in parallel
}
get("/parallel", parallel_handler);
```

> [!TIP]
> 
> - For sequential or single CPU-bound operations, use handler-level worker (`get_worker()`, `post_worker()`, etc.)
> - For independent parallel blocking operations, use `worker()` function

## I/O Bound Async

### Async Database Queries

For asynchronous database queries, Ecewo provides the [ecewo-postgres package](https://github.com/savashn/ecewo-packages/tree/main/postgres), which integrates [libpq](https://www.postgresql.org/docs/current/libpq.html) with Ecewo's event loop ([libuv](https://libuv.org/)) for non-blocking operations. This integration leverages PostgreSQL's native async capabilities, ensuring database queries never block the main thread. See the [Async Postgres Chapter](/docs/examples/async_postgres.md) for detailed usage.

Only PostgreSQL is supported for now. For other databases like MySQL or MongoDB, see their async documentation and consider implementing a similar [libuv](https://libuv.org/)-based integration.

If you would like to use a database that has no async API, such as SQLite, you may still use Ecewo's `worker` routes or functions for blocking performance-critical queries.

## When To Use Each API?

What do you need?
- Database queries? -> `ecewo-postgres.h`
- Parallel database queries? -> `ecewo-postgres.h`
- Single CPU-bound task? -> `*_worker()` route
- Sequential CPU-bound tasks? -> `*_worker()` route
- CPU-bound fire-and-forget background processes? -> `*_worker()` route
- CPU-bound parallel and non-sequential operations? -> `worker()` function
- CPU + Database querying in the same route? -> `*_worker()` + `ecewo-postgres.h`
- Fast and lighweight handlers? → Sync handlers

These three systems together form Ecewo's powerful async capabilities, providing optimized solutions for different use cases.

> [!NOTE]
>
> For fire-and-forget operations, send a response first (it will free the arena memory) and then call the function that will run on the background.
